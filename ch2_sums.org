#+TITLE: Chapter 2: Sums

* Notation

Iverson introduced an interesting notation for describing a strong predicate on a value in a sum:

$\Sigma_k a_k [P(k)]$

if $[P(k)]$ is false or $a_k$ is undefined, the term $a_k [P(k)]$ is also zero, so we can safely include it among the terms being summed.

* Sums and Recurrences

wee doggy, lots going on here. Check the videos from snugglyhappymathtime

* Manipulation of Sums

** Distributive Law

$\Sigma_{k \in K} c a_k = c\Sigma_{k \in K} a_k$

** Associative Law

$\Sigma_{k \in K} (a_k + b_k) = \Sigma_{k \in K} a_k + \Sigma_{k \in K} b_k$

** Commutative Law

$\Sigma_{k \in K} a_k = \Sigma_{p(k) \in K} a_{p(k)}$

Where $p(k)$ means we can partition the terms in any way we please. $p(k)$ is any permutation of the set of *all* integers

For every integer $n$, there should be exactly 1 integer $k$ such that $p(k) = n$

** Combining Different Sets of Indices

if $K$ and $K'$ are any sets of integers, then

$\Sigma_{k \in K} a_k + \Sigma_{k \in K'} a_k = \Sigma_{k \in K \cap K'} a_k + \Sigma_{k \in K \cup K'} a_k$

** Perturbation Method

The operation of splitting off a term is the basis of a *perturbation method* that often allows us to evaluate a sum in closed form

Given $S_n = \Sigma_{0 \leq k \leq n} a_k$

$S_n + a_{n + 1} = a_0 + \Sigma_{0 \leq k \leq n}a_{k + 1}$

* Multiple Sums

** Interchanging the Order of Summation

$\Sigma_j \Sigma_k a_{j, k} [P(j, k)] = \Sigma_{P(j, k)} a_{j,k} = \Sigma_k \Sigma_j a_{j, k} [P(j, k)]$

** General Distributive Law

$\Sigma_{j \in J, k \in K} a_j b_k = (\Sigma_{j \in J} a_j)(\Sigma_{k \in K} b_k)$

** Order of Summation

*** Vanilla

$\Sigma_{j \in J}\Sigma_{k \in K} a_{j, k} = \Sigma_{j \in J, k \in K} a_{j,k} = \Sigma_{k \in K}\Sigma_{j \in J} a_{j, k}$

*** Rocky Road

Applies when the range of an inner sum depends on an index variable of the outer sum

$\Sigma_{j \in J}\Sigma_{k \in K(j)} a_{j, k} = \Sigma_{k \in K'}\Sigma_{j \in J'(k)} a_{j, k}$

*** General Case

$(\Sigma_{k=1}^n a_k)(\Sigma_{k=1}^n b_k) = n \Sigma_{k=1}^n a_k b_k - \Sigma_{1 \leq j < k \leq n} (a_k - a_j)(b_k - b_j)$

*** Chebyshev's Monotonic Inequalities
$(\Sigma_{k=1}^n a_k)(\Sigma_{k=1}^n b_k) \leq n \Sigma_{k=1}^n a_k b_k$ if $a_1 \leq ... \leq a_n$ and $b_1 \leq ... \leq b_n$

$(\Sigma_{k=1}^n a_k)(\Sigma_{k=1}^n b_k) \geq n \Sigma_{k=1}^n a_k b_k$ if $a_1 \leq ... \leq a_n$ and $b_1 \geq ... \geq b_n$

** Index Replacement

What if we replace $k$ by $f(j)$ where $f: J \to K$ that takes an integer $j \in J$ into an integer $f(j) \in K$?

The general formula for index replacement is

$\Sigma_{j \in J} a_{f(j)} = \Sigma_{k \in K} a_k \# f^{-}(k)$

where $\#f^{-}(k)$ stands for the number of elements in the set $f^{-}(k) = \{j | f(j) = k\}$, that is, the number of values $j \in J$ such that $f(j) = k$

Alternatively:

$\Sigma_{a_{f(j)}} = \Sigma_{j \in J, k \in K} a_k [f(j) = k] = \Sigma_{k \in K} a_k \Sigma_{j \in J} [f(j) = k]$

In the special case that $f$ is a one to one correspondence between $J$ and $K$, the general formula reduces to

$\Sigma_{j \in J} a_{f(j)} = \Sigma_{f(j) \in K} a_{f(j)} = \Sigma_{k \in K} a_k$

*** Identity

$\Sigma_{0 \leq k < n} H_k = nH_n - n$

* General Methods
On Build a Repertoire

Reviewing repertoire method

Skipping repertoire method. Will ask during book club

* Finite and Infinite Calculus

Finite calculus is based on the properties of the difference operator, $\Delta$, defined by:

$\Delta f(x) = f(x + 1) - f(x)$

This is essentially the derivative, but with $h = 1$ being fixed

There is a type of "mth" power that makes finite calculus interesting:

Falling Factorial Powers:

$x^{\underline{m}} = x(x - 1)...(x - m + 1)$

Rising Factorial Powers:

$x^{\overline{m}} = x(x + 1)...(x + m - 1)$

When $m = 0$, we have $x^{\underline{0}} = x^{\overline{0}} = 1$

The finite calculus has a handy law to match $D(x^m) = m x^{m - 1}$:

$\Delta(x^{\underline{m}}) = m x^{\underline{m - 1}}$

Analogously, $\Delta$ has an inverse, the anti-difference (or summation) operator $\Sigma$; and there's another Fundamental Theorem:

$g(x) = \Delta f(x) \iff \Sigma g(x) \delta x = f(x) + C$

Here, $\Sigma g(x) \delta x$, the indefinite sum of $g(x)$ is the class of functions whose difference is $g(x)$

Just as infinite calculus has definite integrals, finite calculus has definite sums:

if $g(x) = Df(x)$, then

$\Sigma_a^b g(x) \delta x = f(x) \rvert_a^b = f(b) - f(a)$

where

$\Sigma_a^b g(x) \delta x = \Sigma_{k = a}^{b - 1} g(k) = \Sigma_{a \leq k < b} g(k)$

In other words, the definite sum is the same as an ordinary sum with limits, but excluding the value at the upper limit

$\Sigma_a^b g(x) \delta x + \Sigma_b^c g(x) \delta x = \Sigma_a^c g(x) \delta x$

Integration with falling factorials:

$\Sigma_{0 \leq k < n} k^{\underline{m}} = \frac{k^{\underline{m + 1}}}{m + 1} \rvert_0^n = \frac{n^{\underline{m + 1}}}{m + 1}$


*** Additional Properties

$x^{\underline{n}} = \frac{x}{x^{\overline{n}}}$

$x^{\underline{m + n}} = x^{\underline{m}} (x - m)^{\underline{n}}$

$\Sigma_a^b x^{\underline{m}} \delta x = \frac{x^{\underline{m + 1}}}{m + 1} \rvert_a^b$ if $m \neq -1$
$\Sigma_a^b x^{\underline{m}} \delta x = H_x \rvert_a^b$ if $m = -1$

*** Useful Difference Table


#+DOWNLOADED: screenshot @ 2021-10-11 11:43:47
[[file:Finite_and_Infinite_Calculus/2021-10-11_11-43-47_screenshot.png]]

*** Summation By Parts

$\Delta (u(x)v(x)) = u(x)\Delta v(x) + v(x + 1) \Delta u(x)$

This can be put into a convenient form using the shift operator $E$, defined by $E f(x) = f(x + 1)$

$\Delta (uv) = u \Delta v + E v \Delta u$

$\Sigma u \Delta v = uv - \Sigma Ev \Delta u$

* Infinite Sums

Let $A^+ = \Sigma_{k \in K} a_k^+$ and $A^- = \Sigma_{k \in K} a_k^-$.

If $A^+, A^-$ are both finite, the sum $\Sigma_{k \in K} a_k$ is said to *converge absolutely* to the value $A = A^+ + A^-$
If $A^+ = \infty$ and $A^-$ is finite, the sum diverges to $\infty$ and vice versa with $- \infty$.
If $A^+ = A^- = \infty$, all bets are off

In other words, absolute convergence means that the sum of absolute values converges
